{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Simple Linear Regression (SLR)? Explain its purpose.\n",
        "\n",
        "\n",
        "ans-    \n",
        "    Simple Linear Regression (SLR) is a statistical method that models the\n",
        "    \n",
        "    relationship between a single independent (predictor) variable and a single\n",
        "    \n",
        "    dependent (outcome) variable by fitting a straight line to the data.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "     \n",
        "    Its purpose is to understand how the two variables relate to each other,\n",
        "\n",
        "    to predict future outcomes based on this relationship, and to provide a\n",
        "      \n",
        "    foundation for more complex statistical models."
      ],
      "metadata": {
        "id": "Xxygx8mfQyZl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2: What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "ans-\n",
        "\n",
        "\n",
        "    The key assumptions of Simple Linear Regression are that the relationship\n",
        "    \n",
        "    between the two variables is linear, the errors have constant variance\n",
        "    \n",
        "    (homoscedasticity), the errors are independent of each other,\n",
        "    \n",
        "    and the errors are normally distributed.\n",
        "\n",
        "\n",
        "**Linearity:**    \n",
        "    \n",
        "    \n",
        "    The relationship between the independent and dependent variables is a straight line.\n",
        "\n",
        "\n",
        "**Homoscedasticity:**\n",
        "\n",
        "    The variance of the errors is constant across all levels of the independent variable.\n",
        "\n",
        "\n",
        "**Independence of Errors:**\n",
        "\n",
        "\n",
        "    The errors (residuals) are not correlated with each other. The error for\n",
        "    \n",
        "    \n",
        "    one observation does not affect the error for another.\n",
        "\n",
        "\n",
        "\n",
        "**Normality of Errors:**\n",
        "\n",
        "   \n",
        "    The errors are normally distributed, forming a bell-shaped curve.\n",
        "\n",
        "\n",
        "\n",
        "**Zero conditional mean of errors**:\n",
        "\n",
        "\n",
        "    The expected value of the errors is zero. For simple linear regression,\n",
        "    \n",
        "    this assumption is often covered by the other assumptions.\n",
        "\n",
        "\n",
        "**No multicollinearity**:\n",
        "\n",
        "\n",
        "    This assumption is critical for multiple linear regression,\n",
        "    \n",
        "    but it is not applicable to simple linear regression since there is only\n",
        "    \n",
        "    one independent variable."
      ],
      "metadata": {
        "id": "8psDqq88RqLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3: Write the mathematical equation for a simple linear regression model and\n",
        "explain each term.\n",
        "\n",
        "\n",
        "\n",
        "ans-\n",
        "\n",
        "\n",
        "    The linear regression line equation is typically written as y=a+bx,\n",
        "\n",
        "    where y is the dependent variable, 'x is the independent variable, 'a' is\n",
        "    \n",
        "    the y-intercept, and 'b' is the slope of the line. This equation represents\n",
        "    \n",
        "    the best-fit straight line through a set of data points, showing the linear\n",
        "    \n",
        "    relationship between the variables.\n",
        "\n",
        "\n",
        "\n",
        "    y: The dependent variable, which is the outcome or value being predicted.\n",
        "\n",
        "    x: The independent variable, which is the predictor variable or input.\n",
        "\n",
        "    a: The y-intercept, which is the value of y when x is equal to 0.\n",
        "\n",
        "    b: The slope, which represents the change in y for a one-unit increase in x\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j3um8HtabQUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 4: Provide a real-world example where simple linear regression can be\n",
        "applied?\n",
        "\n",
        "ans-\n",
        "    A real-world example of simple linear regression is predicting a house's\n",
        "   \n",
        "    price based on its square footage. The model uses the square footage as the\n",
        "   \n",
        "    independent variable to predict the price, which is the dependent variable.\n",
        "   \n",
        "    The resulting regression line can show how much the price increases for each\n",
        "   \n",
        "    additional square foot of living space.\n",
        "\n"
      ],
      "metadata": {
        "id": "2IhOsoz7dI2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 5: What is the method of least squares in linear regression?\n",
        "\n",
        " ans-      \n",
        "\n",
        "    The method of least squares in linear regression is a statistical technique\n",
        "    \n",
        "    used to find the best-fitting straight line through a set of data points by\n",
        "    \n",
        "    minimizing the sum of the squared vertical distances (residuals) between\n",
        "    \n",
        "    each data point and the line.\n",
        "\n"
      ],
      "metadata": {
        "id": "y5wp-WRjdnE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6: What is Logistic Regression? How does it differ from Linear Regression?\n",
        "\n",
        "ans-\n",
        "  \n",
        "\n",
        "\n",
        "    Logistic regression predicts the probability of a categorical outcome (like\n",
        "  \n",
        "    \"yes\" or \"no\")\n",
        "  \n",
        "    by modeling a logistic curve, while linear regression predicts\n",
        "  \n",
        "    a continuous value (like price or temperature) using a straight-line\n",
        "  \n",
        "    relationship. The fundamental difference is that logistic regression is for\n",
        "  \n",
        "    classification problems and linear regression is for regression problems.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Logistic Regression**\n",
        "\n",
        "\n",
        "**Purpose:**\n",
        "\n",
        "    To predict a categorical outcome by modeling the probability of an event\n",
        "    \n",
        "    occurring.\n",
        "\n",
        "\n",
        "**Output:**\n",
        "\n",
        "    A probability between 0 and 1, which is then often used to classify data\n",
        "    \n",
        "    into categories (e.g., spam/not-spam).\n",
        "\n",
        "\n",
        "**Model:**\n",
        "\n",
        "    Uses a logistic or sigmoid function to produce an S-shaped curve.\n",
        "\n",
        "\n",
        "**Estimation:**\n",
        "\n",
        "\n",
        "    Typically uses maximum likelihood estimation to find the best-fitting model.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Linear Regression**\n",
        "\n",
        "\n",
        "**Purpose:**\n",
        "\n",
        "    To predict a continuous, numerical outcome.\n",
        "\n",
        "\n",
        "**Output:**\n",
        "\n",
        "    A continuous value that can fall anywhere on the number line (e.g.,\n",
        "    \n",
        "    predicting the price of a house).\n",
        "\n",
        "\n",
        "**Model:**\n",
        "\n",
        "    Uses a linear equation to draw a straight line, assuming a linear\n",
        "    \n",
        "    relationship between variables.\n",
        "\n",
        "\n",
        "**Estimation**:\n",
        "\n",
        "    Typically uses the least squares method to find the line that minimizes\n",
        "    \n",
        "    the distance between the data points and the line."
      ],
      "metadata": {
        "id": "y1p5udMofJ4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7: Name and briefly describe three common evaluation metrics for regression\n",
        "models.\n",
        "\n",
        "ans-\n",
        "\n",
        "    Three common regression metrics are Mean Absolute Error (MAE), Mean Squared\n",
        "    \n",
        "    Error (MSE), and R-squared R square. MAE measures the average absolute\n",
        "     \n",
        "    difference between predicted and actual values, MSE measures the average\n",
        "     \n",
        "    squared difference, and R indicates the proportion of the\n",
        "      \n",
        "    in the dependent variable that is predictable from the independent\n",
        "       \n",
        "    variables."
      ],
      "metadata": {
        "id": "CEx2SeqMgQ2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8: What is the purpose of the R-squared metric in regression analysis?\n",
        "\n",
        "ans-\n",
        "\n",
        "    The purpose of the R-squared metric in regression analysis is to measure the\n",
        "\n",
        "    goodness of fit, showing the proportion of the variance in the dependent\n",
        "\n",
        "    variable that is predictable from the independent variables. Essentially, it\n",
        "\n",
        "    indicates how well the regression model explains the data; a higher R-squared\n",
        "\n",
        "    value means the model's predictions are closer to the actual data points.\n",
        "\n",
        "    An R-squared of 1 means a perfect fit, while an R-squared of 0 means the model explains none of the variability.\n",
        "\n",
        "\n",
        "-> **Measure of goodness of fit :**\n",
        "\n",
        "\n",
        "    R-squared quantifies how well the regression model predicts the outcome.\n",
        "    \n",
        "    It measures the scatter of the data points around the fitted regression line.   \n",
        "\n",
        " ->**Explain varience :**\n",
        "\n",
        "    it represents the peercentage of variaton in the dependent variable  \n",
        "\n",
        "    that is explained by independent variables in the model .\n",
        "\n",
        "\n",
        " ->**Interpretation**:\n",
        "\n",
        "\n",
        "    a value of 1 indicates that the model perfectly predicts the dependent variable\n",
        "\n",
        "    A value of 0 means the model does not explain any of the variability in the dependent variable.\n",
        "    \n",
        "    \n",
        "    A value of 0.76 means that 76% of the variation in the dependent variable is explained by the independent variables.\n",
        "    \n",
        "**Model evaluation:**\n",
        "\n",
        "\n",
        "    R-squared is a key metric used to evaluate the performance of a regression\n",
        "    \n",
        "    model, helping to determine how well the model fits the data.\n",
        "\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "i5vqZKtUg9bT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9: Write Python code to fit a simple linear regression model using scikit-learn\n",
        "and print the slope and intercept.\n"
      ],
      "metadata": {
        "id": "DMlIK3w0jzQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sample data\n",
        "# X should be a 2D array (n_samples, n_features)\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "y = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "# Create a Linear Regression model object\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model to the data\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print the intercept and coefficient (slope for simple linear regression)\n",
        "print(f\"Intercept: {model.intercept_}\")\n",
        "print(f\"Slope (Coefficient): {model.coef_[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb4RtZfdj0Pj",
        "outputId": "6ada347c-0b5a-40db-ae2e-ac6d66b3a11c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intercept: 2.2\n",
            "Slope (Coefficient): 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10: How do you interpret the coefficients in a simple linear regression model?"
      ],
      "metadata": {
        "id": "uQ4Nq7XekCCQ"
      }
    }
  ]
}